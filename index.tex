% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={R guide for Strategic Information Advisors},
  pdfauthor={Lemlem Baraki, Aaron Chafetz, Tim Essam, Baboyma Kagniniwa, Karishma Srikanth},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{R guide for Strategic Information Advisors}
\author{Lemlem Baraki, Aaron Chafetz, Tim Essam, Baboyma Kagniniwa,
Karishma Srikanth}
\date{8/1/23}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[borderline west={3pt}{0pt}{shadecolor}, interior hidden, frame hidden, sharp corners, breakable, boxrule=0pt, enhanced]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\bookmarksetup{startatroot}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

This is a book created from markdown and executable code.

See Chafetz (2023) for additional discussion of literate programming.

\bookmarksetup{startatroot}

\hypertarget{summary}{%
\chapter{Summary}\label{summary}}

In summary, this book has no content whatsoever.

\bookmarksetup{startatroot}

\hypertarget{background}{%
\chapter{Background}\label{background}}

Maintain a standard, living reference guide to establish standard
workflows and for onboard analysts on how to access the great work that
exists and be a contributor as well. See OHA R Analyst Manual -
Purpose/Outline for more details. This guide is not intended to teach
you R, but rather how to orient you to how we have set up and use R
workflows. If you are looking for a getting started with R guide, we
developed a
\href{https://usaid-oha-si.github.io/learn/categories/\#rbbs}{``R
Building Blocks Series''} in 2022 based on
\href{https://r4ds.had.co.nz/}{R for Data Science}.

\hypertarget{who-is-the-audience}{%
\section{Who is the audience?}\label{who-is-the-audience}}

This guide is designed to assist OHA analysts who want to incorporate R
+ RStudio and Git + GitHub into their analytical workflows. While the
primary target audience is new Strategic Information Analysts, the
concepts covered in this guide can be readily applied to workflows
across various areas within OHA.

\hypertarget{how-to-use}{%
\section{How to use}\label{how-to-use}}

This guide is setup to help users setup their R environments on their
local machines

\hypertarget{how-to-contribute}{%
\section{How to contribute}\label{how-to-contribute}}

TO DO

\bookmarksetup{startatroot}

\hypertarget{installing-r-rstudio-rtools}{%
\chapter{Installing R, RStudio,
RTools}\label{installing-r-rstudio-rtools}}

Working from your USAID laptop, Government Furnished Equipment (GFE),
you can install R and RStudio without having to submit a ticket to the
M/CIO Help Desk. R is the open-source statistics package that we use for
our work and is the engine that powers RStudio Desktop, the user
interface or integrated development environment (IDE). RStudio Desktop
or another IDE such as Visual Studio Code is not required to use R, but
will vastly improve your experience.

To install both R and RStudio Desktop on your GFE, go to Software Center
on your computer (Start \textgreater{} Microsoft Endpoint manager
\textgreater{} Software Center) Once there, you can select the
Application called ``R for Windows'' and click ``Install''. After that
completes, you can then select ``RStudio Desktop'' and then ``Install''.
If you run into any issues, first try restarting your machine and if
that fails, you can contact \href{CIO-HELPDESK@usaid.gov}{M/CIO Help
Desk}.

\begin{figure}

{\centering \includegraphics{./images/r_setup-software-center_r.png}

}

\end{figure}

If working on a personal machine, you can install R from
\href{https://cran.r-project.org/}{CRAN}. Select ``Download R for
Windows'' and then ``base'' and follow the instructions for installing
that pop up when you launch the .exe file from your downloads. RStudio
Desktop can be installed
\href{https://posit.co/download/rstudio-desktop/}{Posit's website} by
selecting ``Download RStudio Desktop for Windows'' and then following
the setup instructions.

\hypertarget{installing-rtools}{%
\section{Installing Rtools}\label{installing-rtools}}

If you are working on a GFE, you will need to submit a ticket to
\href{CIO-HELPDESK@usaid.gov}{M/CIO Help Desk} to install Rtools on your
machine. If you are installing from your personal machine, you will need
to \href{https://cran.r-project.org/bin/windows/Rtools/}{download} and
install the version of Rtools based on the R version you are using. You
can determine what version of R you are using by opening up a new
instance of R or RStudio and the version will be the very first thing
that appears in your console.

\hypertarget{rstudio-global-options}{%
\section{RStudio Global Options}\label{rstudio-global-options}}

It's best practice to start with a clean session each time you load up
RStudio, so you will want to adjust some default options in your IDE. To
access these, in the menu bar at the top, navigate to Tools
\textgreater{} Global Options. Here are the places you will want to make
changes to the default options before you hit ``Apply'':

\begin{itemize}
\tightlist
\item
  Uncheck ``Result most recent opened project at startup''
\item
  Uncheck ``Restore .RData into Workspace at startup''
\item
  Change dropdown to ``Never'' for ``Save workspace to .RData on exit''
\item
  Uncheck ``Always save history (even when not saving .RData)
\end{itemize}

\begin{figure}

{\centering \includegraphics{./images/r_setup-global-options.png}

}

\end{figure}

\hypertarget{storing-snippets}{%
\section{Storing Snippets}\label{storing-snippets}}

Rstudio code snippets are predefined code shortcuts that can be used to
quickly insert commonly used code blocks. The use of snippets can
improve coding efficiency, reduce the time spent copying and pasting
code from other scripts, and improve the readability of your code by
providing a standardized format for your analytical scripts.

To create your own snippets in Rstudio, go to ``Tools \textgreater{}
Global Options \textgreater{} Code \textgreater{} Edit Snippets. This
will open a file where you can define your custom snippets using a
simple syntax.

\begin{figure}

{\centering \includegraphics{./images/r_setup-snippets_global-options.png}

}

\end{figure}

Rstudio comes bundled with a set of built-in snippets that you may have
already used without even realizing it. The snippets are not limited to
just R, but to all of the different languages you can code in within the
Rstudio IDE. In the example below, this snippet sets up the formatting
of a script for you. To create a new snippet, follow the syntax in the
window and click save. Your snippet is now available for use.

\begin{figure}

{\centering \includegraphics{./images/r_setup-snippet-window.png}

}

\end{figure}

For example, if we wanted to create snippet to insert a new object that
represents the time right now, we could use the following snippet:

\begin{verbatim}
snippet time “insert time right now”     
   Sys.time()
\end{verbatim}

Close your snippet window by hitting save, and return to the console.

When we start typing we will then see the following appear.

\begin{figure}

{\centering \includegraphics{./images/r_setup-snippet_insert.png}

}

\end{figure}

If we hit Tab, the \texttt{Sys.time()} function will be inserted in the
console window. When we hit enter, Rstudio will report the current time.
While this may not be that useful, you can imagine how useful this may
be if you need to insert the date or a repeated chunk of code.

\hypertarget{types-of-snippets}{%
\section{Types of snippets}\label{types-of-snippets}}

There are broadly four different types of snippets available for use or
creation.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Predefined snippets: RStudio comes with several built-in snippets for
  common programming tasks. These snippets cover a wide range of R code
  structures and functions, such as for loops, if statements, function
  definitions, and more.
\item
  Triggering snippets: Snippets are triggered by typing a specific
  keyword followed by pressing the ``Tab'' key. For example, if you type
  ``for'' and then press ``Tab,'' RStudio will automatically expand the
  snippet into a basic for loop structure.
\item
  Tab stops: Snippets may contain tab stops (usually denoted by the
  \$\{1\}), indicated by numbers or placeholders. These allow you to
  quickly navigate through the different sections of the snippet by
  pressing the ``Tab'' key. For example, if you have a placeholder for a
  variable name, pressing ``Tab'' will move the cursor to that position,
  allowing you to enter the desired variable name.
\item
  Dynamic snippets: Snippets can be dynamic and include placeholders
  that are automatically filled with values based on the context.For
  example, the ``\# DATE: r Sys.Date()'' code chunk will insert today's
  date into your script.
\end{enumerate}

By using RStudio snippets, you can streamline your coding workflow,
reduce repetitive typing, and improve overall productivity when working
with R code. We highly encourage you to take advantage of snippets and
share your discoveries with the team.

\href{https://gist.github.com/tessam30/fc775a2f917ea5d62de0f6724c4aeada}{Link
to SI Snippets}

\hypertarget{additional-resources}{%
\section{Additional Resources}\label{additional-resources}}

\begin{itemize}
\tightlist
\item
  \href{http://jtleek.com/modules/01_DataScientistToolbox/02_10_rtools/\#1}{Installing
  Rtools - Jeffrey Leek}
\item
  \href{https://usaid-oha-si.github.io/corps/rbbs/2022/01/28/rbbs-0-setup.html}{RBBS
  - 0 Software and Account Setup: Setting up Rtools - Aaron Chafetz}
\end{itemize}

\bookmarksetup{startatroot}

\hypertarget{installing-source-sans-pro-typeface}{%
\chapter{Installing Source Sans Pro
Typeface}\label{installing-source-sans-pro-typeface}}

To create standard visualizations across our SI team, we rely on one of
USAID's alternate fonts,
\href{https://fonts.google.com/specimen/Source+Sans+Pro}{Sans Source
Pro}. This typeface is not only not native to R, nor is it a standard to
Windows, but is an open source typeface available from Google Fonts.

\begin{figure}

{\centering \includegraphics{./images/typeface_setup-usaid-style_font.png}

}

\end{figure}

To install the font on your GFE, you can find it in Software Center
(Start \textgreater{} Microsoft Endpoint manager \textgreater{} Software
Center). Once there, you can select the Application called ``Source Sans
Pro'' and click ``Install''.

\begin{figure}

{\centering \includegraphics{./images/typeface_setup-software-center_font.png}

}

\end{figure}

To install it on your computer, navigate to the typeface on
\href{https://fonts.google.com/specimen/Source+Sans+Pro}{Google Fonts}
and click the ``Download family''. After the folder finishes
downloading, unzip it.

\hypertarget{accessing-fonts-in-r}{%
\section{Accessing Fonts in R}\label{accessing-fonts-in-r}}

To use non-native fonts in R, you must run a program called
\texttt{extrafonts}. You will need to run the following code below to
install all the fonts on your computer (if desired) and the one you just
downloaded/added. You will only need to import fonts only once on your
machine. However, to use these fonts with any plotting in R, you will
need to load the \texttt{extrafont} as with any other package.

\begin{verbatim}
#load library (install if these are not already installed)
library(extrafont)  #install.packages("extrafont")
library(remotes)  #install.packages("remotes")

#downgrade a package dependency for extrafont
#https://stackoverflow.com/questions/61204259/how-can-i-resolve-the-no-font-name-issue-when-importing-fonts-into-r-using-ext/68642855#68642855
install_version("Rttf2pt1", version = "1.3.8")

#import all Windows fonts
  font_import()
  
#restart your R session - CTRL + SHIFT + F10

#check that your fonts are now accessible in R
library(extrafont)
fonts()
\end{verbatim}

\begin{figure}

{\centering \includegraphics{./images/typeface_setup-typeface_installed.png}

}

\end{figure}

\hypertarget{additional-resources-1}{%
\section{Additional Resources}\label{additional-resources-1}}

\begin{itemize}
\tightlist
\item
  \href{https://www.usaid.gov/branding/gsm}{USAID Graphic Standards
  Manual}
\item
  \href{https://fonts.google.com/specimen/Source+Sans+Pro}{Google Fonts:
  Sans Source Pro}
\item
  \href{https://stackoverflow.com/questions/61204259/how-can-i-resolve-the-no-font-name-issue-when-importing-fonts-into-r-using-ext/68642855\#68642855}{Stack
  Overflow: Resolve the ``No Font Name Issue''}
\item
  \href{https://usaid-oha-si.github.io/glitr/}{glitr package}
\end{itemize}

\bookmarksetup{startatroot}

\hypertarget{installing-git-git-client}{%
\chapter{Installing git \& git client}\label{installing-git-git-client}}

GitHub serves as a platform for hosting code, facilitating version
control, and enabling collaborative work. It empowers you and your team
to collaborate on projects seamlessly, regardless of your physical
location. To begin using Git and GitHub, a series of essential steps
must be followed to set up and initialize the Git environment:

This can be done at the GitHub website where you can sign up for an
account for free. While you can use your USAID email, you might want to
consider using a personal email to maintain access to your work should
you leave USAID. Once that is created, you will need to be added to the
``USAID-OHA-SI'' organization and appropriate teams, which will be
further outlined in \emph{{[}insert chapter name{]}}\_\_.

\hypertarget{install-or-upgrade-r-and-rstudio}{%
\section{Install or upgrade R and
RStudio}\label{install-or-upgrade-r-and-rstudio}}

Assuming that you've installed R and R Studio as outlined \_\_\_, it is
best to make sure that your installation is upgraded to the most current
version. This ensures that you have all of the latest functionality and
resources.

To make sure your R installation is current, you can check in the
``Console'':

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check what version of R \& Rstudio you are using. Try to use the most recent versions.}
\NormalTok{R.version.string}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "R version 4.2.2 (2022-10-31 ucrt)"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#   Check version of R{-}studio}
\CommentTok{\#Rstudio.Version()}
\CommentTok{\#rstudioapi::getVersion()}
\end{Highlighting}
\end{Shaded}

\bookmarksetup{startatroot}

\hypertarget{setting-up-a-project}{%
\chapter{Setting up a project}\label{setting-up-a-project}}

An R project is a directory that contains all the contents, scripts, and
resources that are related to a specific project. R projects enable us
to group our work into self-contained folders, which is particularly
useful if we have context-specific analyses that we wish to keep
distinct.

The most beneficial aspect of creating an R Project is that the working
directory is the project's roots folder - this allows us to keep track
of all the files that are pertinent to a specific project and easily
read files from the working directory. It also allows us the ability to
preserve our workspace between sessions.

When a project is created, RStudio will create a new R session for the
project. It will allow create the following files:

\begin{itemize}
\tightlist
\item
  An \textbf{.Rproj} file in the project's main directory, which
  contains the same working directory, R session, and command history.
  Previous edited documents and files are restored in editor tabs, as
  well.
\item
  An \textbf{.Rhistory} file in the project's main directory, which
  contains the command history from your session that is loaded into the
  R Project
\item
  An \textbf{.Rdata} file in the project's main directory, which
  contains the data and changes from your sessions to be loaded in the R
  Project
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open RStudio and go to the File menu and select \texttt{New\ Project}.
\item
  In the \texttt{New\ Project} window, choose \texttt{New\ Directory}.
  Then, choose \texttt{New\ Project}. Name your new directory and then
  ``Create the project as subdirectory of'' and select a folder on your
  computer (preferably your folder where you will store all of your R
  Projects). Click on Create Project.
\item
  After your project is completed, if the project does not automatically
  open in RStudio, then go to the File menu, select Open Project, and
  choose the file with the extension \texttt{.Rproj}.
\item
  When RStudio opens, you will see three panels in the window.~ Verify
  your working directory now that we have our Project set up using
  \texttt{getwd()}.
\end{enumerate}

\textbf{Note}: If your RStudio is already opened from an existing
project, you may want to check the \texttt{Open\ in\ a\ new\ session}
checkbox to open the project in a new session.

\bookmarksetup{startatroot}

\hypertarget{installing-our-base-set-of-packages}{%
\chapter{Installing our base set of
packages}\label{installing-our-base-set-of-packages}}

Whereas programs like Stata, SPSS, etc come with a full suite of built
in functions, R is an open source tool with contributions from users all
over the globe. There are some built in functions that come preloaded
with R, but for the most part, you will rely on package from other
contributors. There are tons and tons of packages available on CRAN and
even more hosted elsewhere, like on GitHub. It can be a bit intimidating
to figure out what packages to install from the start, so we will
suggest a handful that we use all the time.

\begin{itemize}
\tightlist
\item
  \textbf{\texttt{dplyr}}: A fast, consistent tool for working with data
  frame like objects, both in memory and out of memory
\item
  \textbf{\texttt{tidyr}} : Tools to help to create tidy data, where
  each column is a variable, each row is an observation, and each cell
  contains a single value. `tidyr' contains tools for changing the shape
  (pivoting) and hierarchy (nesting and `unnesting') of a dataset,
  turning deeply nested lists into rectangular data frames
  (`rectangling'), and extracting values out of string columns. It also
  includes tools for working with missing values (both implicit and
  explicit).
\item
  \textbf{\texttt{ggplot2}}: A system for `declaratively' creating
  graphics, based on The Grammar of Graphics''. You provide the data,
  tell `ggplot2' how to map variables to aesthetics, what graphical
  primitives to use, and it takes care of the details.
\item
  \textbf{\texttt{readr}}: The goal of `readr' is to provide a fast and
  friendly way to read rectangular data (like `csv', `tsv', and `fwf').
  It is designed to flexibly parse many types of data found in the wild,
  while still cleanly failing when data unexpectedly changes
\item
  \textbf{\texttt{readxl}}: Import excel files into R. Supports `.xls'
  via the embedded \href{https://github.com/libxls/libxls}{`libxls' C
  library} and `.xlsx' via the embedded
  \href{https://rapidxml.sourceforge.net/}{`RapidXML' C++ library}.
\item
  \textbf{\texttt{forcats}}: Helpers for reordering factor levels
  (including moving specified levels to front, ordering by first
  appearance, reversing, and randomly shuffling), and tools for
  modifying factor levels (including collapsing rare levels into other,
  `anonymising', and manually `re-coding').
\item
  \textbf{\texttt{stringr}}: A consistent, simple and easy to use set of
  wrappers around the fantastic `stringi' package. All function and
  argument names (and positions) are consistent, all functions deal with
  NA's and zero length vectors in the same way, and the output from one
  function is easy to feed into the input of another.
\item
  \textbf{\texttt{lubridate}}: Functions to work with date-times and
  time-spans: fast and user friendly parsing of date-time data,
  extraction and updating of components of a date-time (years, months,
  days, hours, minutes, and seconds), algebraic manipulation on
  date-time and time-span objects.
\item
  \textbf{\texttt{reprex}}: Convenience wrapper that uses the
  `rmarkdown' package to render small snippets of code to target formats
  that include both code and output.
\item
  \textbf{\texttt{tidyverse}}: The `tidyverse' is a set of packages that
  work in harmony because they share common data representations and
  `API' design. This package is designed to make it easy to install and
  load multiple `tidyverse' packages in a single step.
\item
  \textbf{\texttt{googledrive}}: Manage Google Drive files from R.
\item
  \textbf{\texttt{glue}}: An implementation of interpreted string
  literals, inspired by
  \href{https://www.python.org/dev/peps/pep-0498/}{Python's Literal
  String Interpolation} and
  \href{https://www.python.org/dev/peps/pep-0257/}{Docstrings} and
  \href{https://docs.julialang.org/en/v1.3/manual/strings/\#Triple-Quoted-String-Literals-1}{Julia's
  Triple-Quoted String Literals}
\end{itemize}

\hypertarget{other-packages}{%
\section{\texorpdfstring{\emph{Other
Packages}}{Other Packages}}\label{other-packages}}

\begin{itemize}
\tightlist
\item
  \textbf{`remotes'}: Download and install R packages stored in
  `GitHub', `GitLab', `Bitbucket', `Bioconductor', or plain `subversion'
  or `git' repositories.
\item
  \textbf{\texttt{scales}}: Graphical scales map data to aesthetics, and
  provide methods for automatically determining breaks and labels for
  axes and legends.
\item
  \textbf{\texttt{extrafont}}: Tools to using fonts other than the
  standard PostScript fonts. This package makes it easy to use system
  TrueType fonts and with PDF or PostScript output files, and with
  bitmap output files in Windows.
\item
  \textbf{\texttt{patchwork}}: The `ggplot2' package provides a strong
  API for sequentially building up a plot, but does not concern itself
  with composition of multiple plots. `patchwork' is a package that
  expands the API to allow for arbitrarily complex composition of plots
  by, among others, providing mathematical operators for combining
  multiple plots.
\item
  \textbf{\texttt{datapasta}}: RStudio addins and R functions that make
  copy-pasting vectors and tables to text painless.
\item
  \textbf{\texttt{quickview}}: RStudio addin to quickly inspect data in
  a View tab or open them with default CSV/text editor software.
\end{itemize}

\hypertarget{ohasi-packages}{%
\section{\texorpdfstring{\emph{OHA/SI
Packages}}{OHA/SI Packages}}\label{ohasi-packages}}

\begin{itemize}
\tightlist
\item
  \textbf{\texttt{glitr}}: Helps create and export ggplot2 charts in the
  style used by the GH OHA SI team. Includes multiple styles and themes
  to tweak plots to user needs. Sample testing data also available.
\item
  \textbf{\texttt{glamr}}: Provides a series of base functions useful to
  the GH OHA SI team. This includes project setup, pulling from DATIM,
  and key functions for working with the MSD.
\item
  \textbf{\texttt{gisr}}: R Spatial functions for HIV/AIDS related
  Geospatial Analytics
\item
  \textbf{\texttt{gagglr}}: Since package are developed with a regular
  update cycle, users can often be using outdated packages that resolve
  bug or add new features. This checks to ensure you are using the
  lastest version of the OHA core package and allows you to load them
  all at the start of a session. This package borrows heavily from the
  tidyverse package.
\item
  \textbf{\texttt{tameDP}}: Import PSNUxIM targets and PLHIV data from
  COP Data Pack. The purpose is to make the data tidy and more usable
  than their current structure in the Excel data packs.
\end{itemize}

Whenever you are installing packages, you should start from a clean
instance of R and not load any packages until you are finished
installing what you want. Most packages are found on CRAN and require a
simpler means of installation; others found on GitHub and elsewhere
require a different function to install, specifying the source and
repository.

\begin{verbatim}
#tidyverse packages (all)
install.packages("tidyverse")

#other packages
install.packages("remotes")
install.packages("scales")
install.packages("extrafont")
install.packages("patchwork")
remotes::install_github("MilesMcBain/datapasta")
remotes::install_github("fkeck/quickview")

#USAID-OHA-SI packages
remotes::install_github("USAID-OHA-SI/glitr")
remotes::install_github("USAID-OHA-SI/glamr")
remotes::install_github("USAID-OHA-SI/gisr")
remotes::install_github("USAID-OHA-SI/gagglr")
remotes::install_github("USAID-OHA-SI/tameDP")
\end{verbatim}

\hypertarget{additional-resources-2}{%
\section{Additional Resources}\label{additional-resources-2}}

\begin{itemize}
\tightlist
\item
  \href{https://www.tidyverse.org/}{The Tidyverse Packages}
\item
  \href{https://posit.co/resources/cheatsheets/}{Posit Cheatsheets}
\item
  \href{https://usaid-oha-si.github.io/tools/}{OHA Packages}
\end{itemize}

\bookmarksetup{startatroot}

\hypertarget{storing-and-accessing-pepfar-data}{%
\chapter{Storing and accessing PEPFAR
data}\label{storing-and-accessing-pepfar-data}}

When working on any given project, the general advice is typically to
store your data in that specific project 's repository. This advice is a
good best practice, but does not translate well in the PEPFAR space for
two main reasons: file size and sensitivity. Instead, we recommend
storing PEPFAR structured datasets in a centralized location on your
machine outside of the project,
e.g.~\texttt{C:\textbackslash{}Users\textbackslash{}spower\textbackslash{}Documents\textbackslash{}Data}.

Our work primarily revolves around using PEPFAR structured datasets,
which are large, cumbersome SQLview output files, e.g.~OUxIM, PSNU,
PSNUxIM, NAT\_SUBNAT, and FSD. Given this fact, it makes more sense for
us to store these dataset in a central location on our machines rather
than duplicating these files in each project. These PEPFAR structured
datasets are easily accessible for anyone working in PEPFAR, either from
\href{https://pepfar-panorama.org/}{PEPFAR Panorama} or through the
\href{https://www.datim.org/}{DATIM Genie}.

The second reason for storing these datasets outside of the project is
to avoid any risk of posting these non-public data to a public space
when using version control. While these structured dataset are
aggregated and not individual patient level data, they are not published
by PEPFAR to the public and may contain sensitivities when it comes to
key populations or when using data at the facility level.

For small (and non-PEPFAR structured) datasets, we recommend storing
these data within the project either in the \texttt{Data} and
\texttt{Data\_public} folder. Another alternative is storing the data on
Google Drive in a shared folder and pulling the data down utilizing the
Google API via the \texttt{googledrive} or \texttt{googlesheets4}
packages.

\hypertarget{accessing-pepfar-data}{%
\section{Accessing PEPFAR Data}\label{accessing-pepfar-data}}

PEPFAR maintains a number of different structured datasets across MER,
EA, Budget, and SIMS. Data are entered into DATIM, the system of record,
by partners and goes through an approval process that takes about six
weeks after the quarter ends. In-process data can be accessed through
DATIM and the \href{https://www.datim.org/}{DATIM Genie}, which will
export data in the typical structured manner. Otherwise, datasets are
made available on \href{https://pepfar-panorama.org/}{PEPFAR Panorama}
for download. PEPFAR data can also be pulled directly from DATIM
utilizing an API (see the
\href{https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-240/introduction.html}{DHIS2
API documentation} or our
\href{https://usaid-oha-si.github.io/grabr/}{\texttt{grabr} package}

As mentioned in the last section, we recommend storing these datasets in
a central location on your computer. This creates a problem from a
collaboration standpoint, as we can't just point to the ``Data'' folders
in our project using a relative path; we have to provide a file path
that only works on one user's machine and not another. To solve this
dilemma, we use a function in the
\href{https://usaid-oha-si.github.io/glamr}{\texttt{glamr} package}
called \texttt{si\_paths()} which access the paths we have stored
locally to where our PEPFAR structured datasets reside. This way, when
you pick up a coworker's code, you don't have to change any of the file
paths, it just works.

Those local paths need to be set once and stored in your
\texttt{.Rprofile}. To do so, you will run \texttt{glamr::set\_paths()}
to store all the relevant paths (you can ignore any that aren't relevant
to you). The below example would be the code I would run in the console
indicating where my folders are for the MSD, DATIM files and Downloads.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(glamr)}
\FunctionTok{set\_paths}\NormalTok{(}\AttributeTok{folderpath\_msd =} \StringTok{"\textasciitilde{}/Documents/Data"}\NormalTok{,}
  \AttributeTok{folderpath\_datim =}  \StringTok{"\textasciitilde{}/Documents/DATIM"}\NormalTok{,}
  \AttributeTok{folderpath\_downloads =}  \StringTok{"\textasciitilde{}/Downloads"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{additional-resources-3}{%
\section{Additional Resources}\label{additional-resources-3}}

\begin{itemize}
\tightlist
\item
  \href{https://usaid-oha-si.github.io/glamr/articles/project-workflow.html}{Project
  Workflow Vignette}
\item
  \href{https://usaid-oha-si.github.io/glamr/}{glamr package}
\item
  \href{https://usaid-oha-si.github.io/grabr/}{grabr package}
\item
  \href{https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-240/introduction.html}{DHIS2
  API Documentation}
\end{itemize}

\bookmarksetup{startatroot}

\hypertarget{credential-management}{%
\chapter{Credential management}\label{credential-management}}

While the large majority of our analytic work is using local flat files,
SI analysts have access to a number of different platforms including
PEPFAR DATIM, PEPFAR Panorama, UNAIDS AIDSInfo, USAID Google Drive, and
the USAID's Data Development Commons (DDC) all with their own set of
credentials. \textbf{Passwords, user names, and access keys should never
be stored in scripts}, regardless of whether the script is saved locally
or made available on GitHub. To help ensure this safety measure while
also maximizing reproducibility across our team, we rely on a set of
functions within our inhouse packages,
\href{https://usaid-oha-si.github.io/glamr/}{\texttt{glamr}}. Using
\texttt{glamr} systematize USAID analysts code, calling objects the same
way and in the same locations across machines.

Let's go through an example of how this might be used, starting by
loading the \texttt{glamr} package.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(glamr)}
\end{Highlighting}
\end{Shaded}

Before using credentials you'll need to store them on your local OS. The
\texttt{glamr} package utilizes the \texttt{keyring} package to store
and access the usernames and passwords, storing this information in
Windows' Credential Store.

Let's start by storing our USAID email address, which we will use to
access Google Drive. You'll only be storing your email, not password, as
this is authenticated via standard OAuth2 browser flow. The
\texttt{set\_email()} function also helps you to store your email in
your \texttt{.Rprofile}, allowing \texttt{googledrive::drive\_auth()}
and \texttt{googlesheets4::gs4\_auth()} to run without you having to
enter your email.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set\_email}\NormalTok{(}\StringTok{"spower@usaid.gov"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Next up we'll store our DATIM credentials. For this, you'll need to
enter your DATIM username. When you run the code, you will get a
prompt/pop-up window in RStudio to enter your DATIM password.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set\_datim}\NormalTok{(}\StringTok{"spower"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can also store your PEPFAR Panorama credential, allowing you to
access and download the PEPFAR Structured Datasets. For this, you'll
need to enter your Panorma username. When you run the code, you will get
a prompt/pop-up window in RStudio to enter your Panoma password.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set\_pano}\NormalTok{(}\StringTok{"spower@usaid.gov"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Lastly, if you have access to an Amazon Web Services (s3) account, you
can also store your s3 access and secret keys, which will prompt for the
key and secret.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set\_account}\NormalTok{(}\AttributeTok{name =}\NormalTok{ “s3”)}
\end{Highlighting}
\end{Shaded}

These functions have now passed your credentials in your operating
system's credential manager - Credential Store on Windows and Keychain
on MacOS. We can use \texttt{keyring} to see all the ``services'', or
accounts, stored on your machine.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{keyring}\SpecialCharTok{::}\FunctionTok{key\_list}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{old-way-of-doing-things}{%
\section{Old way of doing things}\label{old-way-of-doing-things}}

Without using the \texttt{glamr} package, analysts would have had to
write out their username and authenticate. Prior to saving and pushing
the code to GitHub, the analyst would have to remove their email.
Another analyst would have to review the code and find where to put
their email in manually if running themselves.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(googlesheets4)}

\CommentTok{\#email}
\NormalTok{  email }\OtherTok{\textless{}{-}} \StringTok{"spower@usaid.gov"} 

\CommentTok{\#authenticate}
  \FunctionTok{gs4\_auth}\NormalTok{(email)}

\CommentTok{\#specific Google Sheet Unique ID (found at the end of the URL)}
\NormalTok{  sheet\_id }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}5mD3ndk08Sdd3dn1dm29smD\textquotesingle{}}
  
\CommentTok{\#read directly into R (similar to read\_csv or read\_xlsx)}
\NormalTok{  df }\OtherTok{\textless{}{-}} \FunctionTok{read\_sheet}\NormalTok{(}\FunctionTok{as\_sheets\_id}\NormalTok{(sheet\_id), }\StringTok{"Sheet1"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

We faced a similar issue with DATIM credentials, where we had to either
write out our username and remove prior to pushing to GitHub or some
analysts stored this information in scripts in different locations on
their different machines, using different object name, eg \texttt{user},
\texttt{myuser}, \texttt{datim\_acct}, \texttt{datim\_login}, etc.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#DATIM user}
\NormalTok{  user }\OtherTok{\textless{}{-}} \StringTok{"spower"}

\CommentTok{\#pull DATIM table of OU/country UIDs and sub{-}national unit levels}
\NormalTok{  ou\_table }\OtherTok{\textless{}{-}} \FunctionTok{datim\_outable}\NormalTok{(user, }\FunctionTok{mypwd}\NormalTok{(user))}
\end{Highlighting}
\end{Shaded}

\hypertarget{accessing-stored-credentials}{%
\section{Accessing stored
credentials}\label{accessing-stored-credentials}}

The old way of doing things was inefficient and posed a risk of posting
credentials accidentally. The previous method required storing the
username in your code and then using it to pull from an encrypted local
file that stored the password associated with the username using
\texttt{glamr::mypwd()}. Each analyst would have to change the username
if they ran the code. The analyst, now, will perform the same task, but
won't have to write out their username in the code since it's loaded
into the session with \texttt{load\_secrets()} and always
assigned/called the same thing.

Now that they're stored after using \texttt{set\_email()} and
\texttt{set\_datim()}, we can load up our credentials at the beginning
of our code and be available for your current R session. In addition to
storing your email, \texttt{load\_secrets()} will authenticate with
Google Drive if you have the \texttt{googledrive} and/or
\texttt{googlesheets4} packages.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load\_secrets}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Your account information is stored for the session in \texttt{Options}
and can be accessed directly via \texttt{getOptions("email")} or
\texttt{getOptions("datim")}. We also have two wrapper functions to pull
your DATIM information since you may need to include that in an API
request - \texttt{datim\_user()} and \texttt{datim\_pwd()}

How does this help? Instead of having to manually enter your USAID
email, it can be loaded automatically and already authenticated for
Google API by running \texttt{load\_secrets()}. The user can also
specify which authentication they want to provide in a session, rather
than loading all of them. For example, you could just specify to
authenticate for use with Google Drive and Sheets -
\texttt{load\_secrets("email")}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(googlesheets4)}
\FunctionTok{library}\NormalTok{(glamr)}

\CommentTok{\#setup session}
  \FunctionTok{load\_secrets}\NormalTok{()}

\CommentTok{\#specific Google Sheet Unique ID (found at the end of the URL)}
\NormalTok{  sheet\_id }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}5mD3ndk08Sdd3dn1dm29smD\textquotesingle{}}

\CommentTok{\#read directly into R (similar to read\_csv or read\_xlsx)}
\NormalTok{  df }\OtherTok{\textless{}{-}} \FunctionTok{read\_sheet}\NormalTok{(}\FunctionTok{as\_sheets\_id}\NormalTok{(sheet\_id), }\StringTok{"Sheet1"}\NormalTok{)}
  
\CommentTok{\#pull DATIM table of OU/country UIDs and sub{-}national unit levels}
\NormalTok{  ou\_table }\OtherTok{\textless{}{-}} \FunctionTok{datim\_outable}\NormalTok{(}\FunctionTok{datim\_user}\NormalTok{(), }\FunctionTok{datim\_pwd}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\bookmarksetup{startatroot}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-chafetz23}{}}%
Chafetz, Aaron H. 2023. {``R Guide for Strategic Information
Advisors.''} \emph{Stractegic Info.} 1 (1): 00--99.
\url{https://doi.org/10.1093/comjnl/27.2.97}.

\end{CSLReferences}



\end{document}

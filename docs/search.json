[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R guide for Strategic Information Advisors",
    "section": "",
    "text": "Preface\nWelcome to the first edition of R Guide for Strategic Information Advisers!\nThis edition is an initial release of the manual in anticipation of the PEPFAR/USAID Data Workshop scheduled for later this summer. This manual will be used as a supporting material for R Track sessions during the workshop as well as regular reference document for new and current staffing using R as their primary analytics tool.\nThe main sections of the manual are:\n\nGuidance on how to install and configure R, RStudio, RTools, base R packages, Fonts and git, as well as structure R Projects to support reproducibility.\nBest practices on how to access and work with data, write R scripts.\nResources on how to use GitHub, GitHub Organization, and reprex to speedy assistance.\nDocumentation on how to develop R Packages and corresponding vignettes, create GitHub Pages, and a personal profile.\nTips and Tricks."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Chafetz (2023) for additional discussion of literate programming.\n\n\n\n\nChafetz, Aaron H. 2023. “R Guide for Strategic Information Advisors.” Stractegic Info. 1 (1): 00–99. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "Summary is forth coming ..."
  },
  {
    "objectID": "background.html#purpose",
    "href": "background.html#purpose",
    "title": "3  Background",
    "section": "3.1 Purpose",
    "text": "3.1 Purpose\nMaintain a standard, living reference guide to establish standard workflows and for onboard analysts on how to access the great work that exists and be a contributor as well. See OHA R Analyst Manual - Purpose/Outline for more details. This guide is not intended to teach you R, but rather how to orient you to how we have set up and use R workflows. If you are looking for a getting started with R guide, we developed a “R Building Blocks Series” in 2022 based on R for Data Science."
  },
  {
    "objectID": "background.html#who-is-the-audience",
    "href": "background.html#who-is-the-audience",
    "title": "3  Background",
    "section": "3.2 Who is the audience?",
    "text": "3.2 Who is the audience?\nThis guide is designed to assist OHA analysts who want to incorporate R + RStudio and Git + GitHub into their analytical workflows. While the primary target audience is new Strategic Information Analysts, the concepts covered in this guide can be readily applied to workflows across various areas within OHA."
  },
  {
    "objectID": "background.html#how-to-use",
    "href": "background.html#how-to-use",
    "title": "3  Background",
    "section": "3.3 How to use",
    "text": "3.3 How to use\nThis guide is setup to help users setup their R environments on their local machines"
  },
  {
    "objectID": "background.html#how-to-contribute",
    "href": "background.html#how-to-contribute",
    "title": "3  Background",
    "section": "3.4 How to contribute",
    "text": "3.4 How to contribute\nTO DO"
  },
  {
    "objectID": "r_setup.html#installing-r-and-rstudio",
    "href": "r_setup.html#installing-r-and-rstudio",
    "title": "4  Installing R, RStudio, RTools",
    "section": "4.1 Installing R and RStudio",
    "text": "4.1 Installing R and RStudio\nWorking from your USAID laptop, Government Furnished Equipment (GFE), you can install R and RStudio without having to submit a ticket to the M/CIO Help Desk. R is the open-source statistics package that we use for our work and is the engine that powers RStudio Desktop, the user interface or integrated development environment (IDE). RStudio Desktop or another IDE such as Visual Studio Code is not required to use R, but will vastly improve your experience.\nTo install both R and RStudio Desktop on your GFE, go to Software Center on your computer (Start > Microsoft Endpoint manager > Software Center) Once there, you can select the Application called “R for Windows” and click “Install”. After that completes, you can then select “RStudio Desktop” and then “Install”. If you run into any issues, first try restarting your machine and if that fails, you can contact M/CIO Help Desk.\n\nIf working on a personal machine, you can install R from CRAN. Select “Download R for Windows” and then “base” and follow the instructions for installing that pop up when you launch the .exe file from your downloads. RStudio Desktop can be installed Posit’s website by selecting “Download RStudio Desktop for Windows” and then following the setup instructions."
  },
  {
    "objectID": "r_setup.html#installing-rtools",
    "href": "r_setup.html#installing-rtools",
    "title": "4  Installing R, RStudio, RTools",
    "section": "4.2 Installing Rtools",
    "text": "4.2 Installing Rtools\nIf you are working on a GFE, you will need to submit a ticket to M/CIO Help Desk to install Rtools on your machine. If you are installing from your personal machine, you will need to download and install the version of Rtools based on the R version you are using. You can determine what version of R you are using by opening up a new instance of R or RStudio and the version will be the very first thing that appears in your console."
  },
  {
    "objectID": "r_setup.html#rstudio-global-options",
    "href": "r_setup.html#rstudio-global-options",
    "title": "4  Installing R, RStudio, RTools",
    "section": "4.3 RStudio Global Options",
    "text": "4.3 RStudio Global Options\nIt’s best practice to start with a clean session each time you load up RStudio, so you will want to adjust some default options in your IDE. To access these, in the menu bar at the top, navigate to Tools > Global Options. Here are the places you will want to make changes to the default options before you hit “Apply”:\n\nUncheck “Result most recent opened project at startup”\nUncheck “Restore .RData into Workspace at startup”\nChange dropdown to “Never” for “Save workspace to .RData on exit”\nUncheck “Always save history (even when not saving .RData)"
  },
  {
    "objectID": "r_setup.html#storing-snippets",
    "href": "r_setup.html#storing-snippets",
    "title": "4  Installing R, RStudio, RTools",
    "section": "4.4 Storing Snippets",
    "text": "4.4 Storing Snippets\nRstudio code snippets are predefined code shortcuts that can be used to quickly insert commonly used code blocks. The use of snippets can improve coding efficiency, reduce the time spent copying and pasting code from other scripts, and improve the readability of your code by providing a standardized format for your analytical scripts.\nTo create your own snippets in Rstudio, go to “Tools > Global Options > Code > Edit Snippets. This will open a file where you can define your custom snippets using a simple syntax.\n\nRstudio comes bundled with a set of built-in snippets that you may have already used without even realizing it. The snippets are not limited to just R, but to all of the different languages you can code in within the Rstudio IDE. In the example below, this snippet sets up the formatting of a script for you. To create a new snippet, follow the syntax in the window and click save. Your snippet is now available for use.\n\nFor example, if we wanted to create snippet to insert a new object that represents the time right now, we could use the following snippet:\nsnippet time “insert time right now”     \n   Sys.time()\nClose your snippet window by hitting save, and return to the console.\nWhen we start typing we will then see the following appear.\n\nIf we hit Tab, the Sys.time() function will be inserted in the console window. When we hit enter, Rstudio will report the current time. While this may not be that useful, you can imagine how useful this may be if you need to insert the date or a repeated chunk of code."
  },
  {
    "objectID": "r_setup.html#types-of-snippets",
    "href": "r_setup.html#types-of-snippets",
    "title": "4  Installing R, RStudio, RTools",
    "section": "4.5 Types of snippets",
    "text": "4.5 Types of snippets\nThere are broadly four different types of snippets available for use or creation.\n\nPredefined snippets: RStudio comes with several built-in snippets for common programming tasks. These snippets cover a wide range of R code structures and functions, such as for loops, if statements, function definitions, and more.\nTriggering snippets: Snippets are triggered by typing a specific keyword followed by pressing the “Tab” key. For example, if you type “for” and then press “Tab,” RStudio will automatically expand the snippet into a basic for loop structure.\nTab stops: Snippets may contain tab stops (usually denoted by the ${1}), indicated by numbers or placeholders. These allow you to quickly navigate through the different sections of the snippet by pressing the “Tab” key. For example, if you have a placeholder for a variable name, pressing “Tab” will move the cursor to that position, allowing you to enter the desired variable name.\nDynamic snippets: Snippets can be dynamic and include placeholders that are automatically filled with values based on the context.For example, the “# DATE: r Sys.Date()” code chunk will insert today’s date into your script.\n\nBy using RStudio snippets, you can streamline your coding workflow, reduce repetitive typing, and improve overall productivity when working with R code. We highly encourage you to take advantage of snippets and share your discoveries with the team.\nLink to SI Snippets"
  },
  {
    "objectID": "r_setup.html#additional-resources",
    "href": "r_setup.html#additional-resources",
    "title": "4  Installing R, RStudio, RTools",
    "section": "4.6 Additional Resources",
    "text": "4.6 Additional Resources\n\nInstalling Rtools - Jeffrey Leek\nRBBS - 0 Software and Account Setup: Setting up Rtools - Aaron Chafetz"
  },
  {
    "objectID": "typeface_setup.html#installing-source-sans-pro",
    "href": "typeface_setup.html#installing-source-sans-pro",
    "title": "5  Installing Source Sans Pro Typeface",
    "section": "5.1 Installing Source Sans Pro",
    "text": "5.1 Installing Source Sans Pro\nTo create standard visualizations across our SI team, we rely on one of USAID’s alternate fonts, Sans Source Pro. This typeface is not only not native to R, nor is it a standard to Windows, but is an open source typeface available from Google Fonts.\n\nTo install the font on your GFE, you can find it in Software Center (Start > Microsoft Endpoint manager > Software Center). Once there, you can select the Application called “Source Sans Pro” and click “Install”.\n\nTo install it on your computer, navigate to the typeface on Google Fonts and click the “Download family”. After the folder finishes downloading, unzip it."
  },
  {
    "objectID": "typeface_setup.html#accessing-fonts-in-r",
    "href": "typeface_setup.html#accessing-fonts-in-r",
    "title": "5  Installing Source Sans Pro Typeface",
    "section": "5.2 Accessing Fonts in R",
    "text": "5.2 Accessing Fonts in R\nTo use non-native fonts in R, you must run a program called extrafonts. You will need to run the following code below to install all the fonts on your computer (if desired) and the one you just downloaded/added. You will only need to import fonts only once on your machine. However, to use these fonts with any plotting in R, you will need to load the extrafont as with any other package.\n#load library (install if these are not already installed)\nlibrary(extrafont)  #install.packages(\"extrafont\")\nlibrary(remotes)  #install.packages(\"remotes\")\n\n#downgrade a package dependency for extrafont\n#https://stackoverflow.com/questions/61204259/how-can-i-resolve-the-no-font-name-issue-when-importing-fonts-into-r-using-ext/68642855#68642855\ninstall_version(\"Rttf2pt1\", version = \"1.3.8\")\n\n#import all Windows fonts\n  font_import()\n  \n#restart your R session - CTRL + SHIFT + F10\n\n#check that your fonts are now accessible in R\nlibrary(extrafont)\nfonts()"
  },
  {
    "objectID": "typeface_setup.html#additional-resources",
    "href": "typeface_setup.html#additional-resources",
    "title": "5  Installing Source Sans Pro Typeface",
    "section": "5.3 Additional Resources",
    "text": "5.3 Additional Resources\n\nUSAID Graphic Standards Manual\nGoogle Fonts: Sans Source Pro\nStack Overflow: Resolve the “No Font Name Issue”\nglitr package"
  },
  {
    "objectID": "git_setup.html#register-a-github-account",
    "href": "git_setup.html#register-a-github-account",
    "title": "6  Installing git & git client",
    "section": "6.1 Register a GitHub account",
    "text": "6.1 Register a GitHub account\nThis can be done at the GitHub website where you can sign up for an account for free. While you can use your USAID email, you might want to consider using a personal email to maintain access to your work should you leave USAID. Once that is created, you will need to be added to the “USAID-OHA-SI” organization and appropriate teams, which will be further outlined in [insert chapter name]__."
  },
  {
    "objectID": "git_setup.html#install-or-upgrade-r-and-rstudio",
    "href": "git_setup.html#install-or-upgrade-r-and-rstudio",
    "title": "6  Installing git & git client",
    "section": "6.2 Install or upgrade R and RStudio",
    "text": "6.2 Install or upgrade R and RStudio\nAssuming that you’ve installed R and R Studio as outlined ___, it is best to make sure that your installation is upgraded to the most current version. This ensures that you have all of the latest functionality and resources.\nTo make sure your R installation is current, you can check in the “Console”:\n\n# Check what version of R & Rstudio you are using. Try to use the most recent versions.\nR.version.string\n\n[1] \"R version 4.2.2 (2022-10-31 ucrt)\"\n\n\n\n#   Check version of R-studio\n#Rstudio.Version()\n#rstudioapi::getVersion()"
  },
  {
    "objectID": "r_project_setup.html#creating-a-new-r-project-in-rstudio",
    "href": "r_project_setup.html#creating-a-new-r-project-in-rstudio",
    "title": "7  Setting up a project",
    "section": "7.1 Creating a new R Project in RStudio",
    "text": "7.1 Creating a new R Project in RStudio\n\nOpen RStudio and go to the File menu and select New Project.\nIn the New Project window, choose New Directory. Then, choose New Project. Name your new directory and then “Create the project as subdirectory of” and select a folder on your computer (preferably your folder where you will store all of your R Projects). Click on Create Project.\nAfter your project is completed, if the project does not automatically open in RStudio, then go to the File menu, select Open Project, and choose the file with the extension .Rproj.\nWhen RStudio opens, you will see three panels in the window.  Verify your working directory now that we have our Project set up using getwd().\n\nNote: If your RStudio is already opened from an existing project, you may want to check the Open in a new session checkbox to open the project in a new session."
  },
  {
    "objectID": "base_packages.html#tidyverse-packages",
    "href": "base_packages.html#tidyverse-packages",
    "title": "8  Installing our base set of packages",
    "section": "8.1 Tidyverse Packages",
    "text": "8.1 Tidyverse Packages\n\ndplyr: A fast, consistent tool for working with data frame like objects, both in memory and out of memory\ntidyr : Tools to help to create tidy data, where each column is a variable, each row is an observation, and each cell contains a single value. ‘tidyr’ contains tools for changing the shape (pivoting) and hierarchy (nesting and ‘unnesting’) of a dataset, turning deeply nested lists into rectangular data frames (‘rectangling’), and extracting values out of string columns. It also includes tools for working with missing values (both implicit and explicit).\nggplot2: A system for ‘declaratively’ creating graphics, based on The Grammar of Graphics”. You provide the data, tell ‘ggplot2’ how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.\nreadr: The goal of ‘readr’ is to provide a fast and friendly way to read rectangular data (like ‘csv’, ‘tsv’, and ‘fwf’). It is designed to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes\nreadxl: Import excel files into R. Supports ‘.xls’ via the embedded ‘libxls’ C library and ‘.xlsx’ via the embedded ‘RapidXML’ C++ library.\nforcats: Helpers for reordering factor levels (including moving specified levels to front, ordering by first appearance, reversing, and randomly shuffling), and tools for modifying factor levels (including collapsing rare levels into other, ‘anonymising’, and manually ‘re-coding’).\nstringr: A consistent, simple and easy to use set of wrappers around the fantastic ‘stringi’ package. All function and argument names (and positions) are consistent, all functions deal with NA’s and zero length vectors in the same way, and the output from one function is easy to feed into the input of another.\nlubridate: Functions to work with date-times and time-spans: fast and user friendly parsing of date-time data, extraction and updating of components of a date-time (years, months, days, hours, minutes, and seconds), algebraic manipulation on date-time and time-span objects.\nreprex: Convenience wrapper that uses the ‘rmarkdown’ package to render small snippets of code to target formats that include both code and output.\ntidyverse: The ‘tidyverse’ is a set of packages that work in harmony because they share common data representations and ‘API’ design. This package is designed to make it easy to install and load multiple ‘tidyverse’ packages in a single step.\ngoogledrive: Manage Google Drive files from R.\nglue: An implementation of interpreted string literals, inspired by Python’s Literal String Interpolation and Docstrings and Julia’s Triple-Quoted String Literals"
  },
  {
    "objectID": "base_packages.html#other-packages",
    "href": "base_packages.html#other-packages",
    "title": "8  Installing our base set of packages",
    "section": "8.2 Other Packages",
    "text": "8.2 Other Packages\n\n‘remotes’: Download and install R packages stored in ‘GitHub’, ‘GitLab’, ‘Bitbucket’, ‘Bioconductor’, or plain ‘subversion’ or ‘git’ repositories.\nscales: Graphical scales map data to aesthetics, and provide methods for automatically determining breaks and labels for axes and legends.\nextrafont: Tools to using fonts other than the standard PostScript fonts. This package makes it easy to use system TrueType fonts and with PDF or PostScript output files, and with bitmap output files in Windows.\npatchwork: The ‘ggplot2’ package provides a strong API for sequentially building up a plot, but does not concern itself with composition of multiple plots. ‘patchwork’ is a package that expands the API to allow for arbitrarily complex composition of plots by, among others, providing mathematical operators for combining multiple plots.\ndatapasta: RStudio addins and R functions that make copy-pasting vectors and tables to text painless.\nquickview: RStudio addin to quickly inspect data in a View tab or open them with default CSV/text editor software."
  },
  {
    "objectID": "base_packages.html#ohasi-packages",
    "href": "base_packages.html#ohasi-packages",
    "title": "8  Installing our base set of packages",
    "section": "8.3 OHA/SI Packages",
    "text": "8.3 OHA/SI Packages\n\nglitr: Helps create and export ggplot2 charts in the style used by the GH OHA SI team. Includes multiple styles and themes to tweak plots to user needs. Sample testing data also available.\nglamr: Provides a series of base functions useful to the GH OHA SI team. This includes project setup, pulling from DATIM, and key functions for working with the MSD.\ngisr: R Spatial functions for HIV/AIDS related Geospatial Analytics\ngagglr: Since package are developed with a regular update cycle, users can often be using outdated packages that resolve bug or add new features. This checks to ensure you are using the lastest version of the OHA core package and allows you to load them all at the start of a session. This package borrows heavily from the tidyverse package.\ntameDP: Import PSNUxIM targets and PLHIV data from COP Data Pack. The purpose is to make the data tidy and more usable than their current structure in the Excel data packs.\n\nWhenever you are installing packages, you should start from a clean instance of R and not load any packages until you are finished installing what you want. Most packages are found on CRAN and require a simpler means of installation; others found on GitHub and elsewhere require a different function to install, specifying the source and repository.\n#tidyverse packages (all)\ninstall.packages(\"tidyverse\")\n\n#other packages\ninstall.packages(\"remotes\")\ninstall.packages(\"scales\")\ninstall.packages(\"extrafont\")\ninstall.packages(\"patchwork\")\nremotes::install_github(\"MilesMcBain/datapasta\")\nremotes::install_github(\"fkeck/quickview\")\n\n#USAID-OHA-SI packages\nremotes::install_github(\"USAID-OHA-SI/glitr\")\nremotes::install_github(\"USAID-OHA-SI/glamr\")\nremotes::install_github(\"USAID-OHA-SI/gisr\")\nremotes::install_github(\"USAID-OHA-SI/gagglr\")\nremotes::install_github(\"USAID-OHA-SI/tameDP\")"
  },
  {
    "objectID": "base_packages.html#additional-resources",
    "href": "base_packages.html#additional-resources",
    "title": "8  Installing our base set of packages",
    "section": "8.4 Additional Resources",
    "text": "8.4 Additional Resources\n\nThe Tidyverse Packages\nPosit Cheatsheets\nOHA Packages"
  },
  {
    "objectID": "creds_mgmt.html#store-credentials",
    "href": "creds_mgmt.html#store-credentials",
    "title": "9  Credential management",
    "section": "9.1 Store credentials",
    "text": "9.1 Store credentials\nBefore using credentials you’ll need to store them on your local OS. The glamr package utilizes the keyring package to store and access the usernames and passwords, storing this information in Windows’ Credential Store.\nLet’s start by storing our USAID email address, which we will use to access Google Drive. You’ll only be storing your email, not password, as this is authenticated via standard OAuth2 browser flow. The set_email() function also helps you to store your email in your .Rprofile, allowing googledrive::drive_auth() and googlesheets4::gs4_auth() to run without you having to enter your email.\n\nset_email(\"spower@usaid.gov\")\n\nNext up we’ll store our DATIM credentials. For this, you’ll need to enter your DATIM username. When you run the code, you will get a prompt/pop-up window in RStudio to enter your DATIM password.\n\nset_datim(\"spower\")\n\nYou can also store your PEPFAR Panorama credential, allowing you to access and download the PEPFAR Structured Datasets. For this, you’ll need to enter your Panorma username. When you run the code, you will get a prompt/pop-up window in RStudio to enter your Panoma password.\n\nset_pano(\"spower@usaid.gov\")\n\nLastly, if you have access to an Amazon Web Services (s3) account, you can also store your s3 access and secret keys, which will prompt for the key and secret.\n\nset_account(name = “s3”)\n\nThese functions have now passed your credentials in your operating system’s credential manager - Credential Store on Windows and Keychain on MacOS. We can use keyring to see all the “services”, or accounts, stored on your machine.\n\nkeyring::key_list()"
  },
  {
    "objectID": "creds_mgmt.html#old-way-of-doing-things",
    "href": "creds_mgmt.html#old-way-of-doing-things",
    "title": "9  Credential management",
    "section": "9.2 Old way of doing things",
    "text": "9.2 Old way of doing things\nWithout using the glamr package, analysts would have had to write out their username and authenticate. Prior to saving and pushing the code to GitHub, the analyst would have to remove their email. Another analyst would have to review the code and find where to put their email in manually if running themselves.\n\nlibrary(googlesheets4)\n\n#email\n  email <- \"spower@usaid.gov\" \n\n#authenticate\n  gs4_auth(email)\n\n#specific Google Sheet Unique ID (found at the end of the URL)\n  sheet_id <- '5mD3ndk08Sdd3dn1dm29smD'\n  \n#read directly into R (similar to read_csv or read_xlsx)\n  df <- read_sheet(as_sheets_id(sheet_id), \"Sheet1\")  \n\nWe faced a similar issue with DATIM credentials, where we had to either write out our username and remove prior to pushing to GitHub or some analysts stored this information in scripts in different locations on their different machines, using different object name, eg user, myuser, datim_acct, datim_login, etc.\n\n#DATIM user\n  user <- \"spower\"\n\n#pull DATIM table of OU/country UIDs and sub-national unit levels\n  ou_table <- datim_outable(user, mypwd(user))"
  },
  {
    "objectID": "creds_mgmt.html#accessing-stored-credentials",
    "href": "creds_mgmt.html#accessing-stored-credentials",
    "title": "9  Credential management",
    "section": "9.3 Accessing stored credentials",
    "text": "9.3 Accessing stored credentials\nThe old way of doing things was inefficient and posed a risk of posting credentials accidentally. The previous method required storing the username in your code and then using it to pull from an encrypted local file that stored the password associated with the username using glamr::mypwd(). Each analyst would have to change the username if they ran the code. The analyst, now, will perform the same task, but won’t have to write out their username in the code since it’s loaded into the session with load_secrets() and always assigned/called the same thing.\nNow that they’re stored after using set_email() and set_datim(), we can load up our credentials at the beginning of our code and be available for your current R session. In addition to storing your email, load_secrets() will authenticate with Google Drive if you have the googledrive and/or googlesheets4 packages.\n\nload_secrets()\n\nYour account information is stored for the session in Options and can be accessed directly via getOptions(\"email\") or getOptions(\"datim\"). We also have two wrapper functions to pull your DATIM information since you may need to include that in an API request - datim_user() and datim_pwd()\nHow does this help? Instead of having to manually enter your USAID email, it can be loaded automatically and already authenticated for Google API by running load_secrets(). The user can also specify which authentication they want to provide in a session, rather than loading all of them. For example, you could just specify to authenticate for use with Google Drive and Sheets - load_secrets(\"email\").\n\nlibrary(googlesheets4)\nlibrary(glamr)\n\n#setup session\n  load_secrets()\n\n#specific Google Sheet Unique ID (found at the end of the URL)\n  sheet_id <- '5mD3ndk08Sdd3dn1dm29smD'\n\n#read directly into R (similar to read_csv or read_xlsx)\n  df <- read_sheet(as_sheets_id(sheet_id), \"Sheet1\")\n  \n#pull DATIM table of OU/country UIDs and sub-national unit levels\n  ou_table <- datim_outable(datim_user(), datim_pwd())"
  },
  {
    "objectID": "access_store_data.html#storing-pepfar-data",
    "href": "access_store_data.html#storing-pepfar-data",
    "title": "10  Storing and accessing PEPFAR data",
    "section": "10.1 Storing PEPFAR Data",
    "text": "10.1 Storing PEPFAR Data\nWhen working on any given project, the general advice is typically to store your data in that specific project ’s repository. This advice is a good best practice, but does not translate well in the PEPFAR space for two main reasons: file size and sensitivity. Instead, we recommend storing PEPFAR structured datasets in a centralized location on your machine outside of the project, e.g. C:\\Users\\spower\\Documents\\Data.\nOur work primarily revolves around using PEPFAR structured datasets, which are large, cumbersome SQLview output files, e.g. OUxIM, PSNU, PSNUxIM, NAT_SUBNAT, and FSD. Given this fact, it makes more sense for us to store these dataset in a central location on our machines rather than duplicating these files in each project. These PEPFAR structured datasets are easily accessible for anyone working in PEPFAR, either from PEPFAR Panorama or through the DATIM Genie.\nThe second reason for storing these datasets outside of the project is to avoid any risk of posting these non-public data to a public space when using version control. While these structured dataset are aggregated and not individual patient level data, they are not published by PEPFAR to the public and may contain sensitivities when it comes to key populations or when using data at the facility level.\nFor small (and non-PEPFAR structured) datasets, we recommend storing these data within the project either in the Data and Data_public folder. Another alternative is storing the data on Google Drive in a shared folder and pulling the data down utilizing the Google API via the googledrive or googlesheets4 packages."
  },
  {
    "objectID": "access_store_data.html#accessing-pepfar-data",
    "href": "access_store_data.html#accessing-pepfar-data",
    "title": "10  Storing and accessing PEPFAR data",
    "section": "10.2 Accessing PEPFAR Data",
    "text": "10.2 Accessing PEPFAR Data\nPEPFAR maintains a number of different structured datasets across MER, EA, Budget, and SIMS. Data are entered into DATIM, the system of record, by partners and goes through an approval process that takes about six weeks after the quarter ends. In-process data can be accessed through DATIM and the DATIM Genie, which will export data in the typical structured manner. Otherwise, datasets are made available on PEPFAR Panorama for download. PEPFAR data can also be pulled directly from DATIM utilizing an API (see the DHIS2 API documentation or our grabr package\nAs mentioned in the last section, we recommend storing these datasets in a central location on your computer. This creates a problem from a collaboration standpoint, as we can’t just point to the “Data” folders in our project using a relative path; we have to provide a file path that only works on one user’s machine and not another. To solve this dilemma, we use a function in the glamr package called si_paths() which access the paths we have stored locally to where our PEPFAR structured datasets reside. This way, when you pick up a coworker’s code, you don’t have to change any of the file paths, it just works.\nThose local paths need to be set once and stored in your .Rprofile. To do so, you will run glamr::set_paths() to store all the relevant paths (you can ignore any that aren’t relevant to you). The below example would be the code I would run in the console indicating where my folders are for the MSD, DATIM files and Downloads.\n\nlibrary(glamr)\nset_paths(folderpath_msd = \"~/Documents/Data\",\n  folderpath_datim =  \"~/Documents/DATIM\",\n  folderpath_downloads =  \"~/Downloads\")"
  },
  {
    "objectID": "access_store_data.html#additional-resources",
    "href": "access_store_data.html#additional-resources",
    "title": "10  Storing and accessing PEPFAR data",
    "section": "10.3 Additional Resources",
    "text": "10.3 Additional Resources\n\nProject Workflow Vignette\nglamr package\ngrabr package\nDHIS2 API Documentation"
  },
  {
    "objectID": "best_practices.html#organizing-your-r-scripts",
    "href": "best_practices.html#organizing-your-r-scripts",
    "title": "11  Best practices on writing a script",
    "section": "11.1 Organizing your R scripts",
    "text": "11.1 Organizing your R scripts\nR Scripts read just like documents do. We have lines of code that R reads top-down and executes, with specific steps built off of what was done previously.\nWe can organize our scripts with a similar flow to organizing a document, to clean up the script visually and help you and others better understand what each part of the script is used for. We can utilize comments to add headers into our script for organization.\nWhile there is no one right way to organize a script, here is an example of how we tend to set up our scripts within OHA/SI. Check out the [Storing Snippets Section] to see how you can easily add this to beginning of each of your scripts.\n\nIntroduction: name of author, purpose of script, date, reference id, notes\nLoad Dependencies and Libraries\nDefine global options or functions: set up global variables as well (variables you want to call on throughout the script)\nImport Data\nData Cleaning\nAnalysis/Visualization\nExport\n\n\n# AUTHOR:   S. Powers | USAID\n# PURPOSE:  Set up training script\n# REF ID:   c2e621bd \n# LICENSE:  MIT\n# DATE:     2022-09-14\n# UPDATED: \n\n# DEPENDENCIES ------------------------------------------------------------\n  \n# LOAD PACKAGES ------------------------------------------------------------\n\n  library(glamr)\n  library(tidyverse)\n  \n\n# GLOBAL VARIABLES --------------------------------------------------------\n    \n  #Grab metadata\n  msd_source <- source_info(file_path)\n  \n  ref_id <- \"c2e621bd\"\n\n# IMPORT ------------------------------------------------------------------\n  \n  #IMPORT MSD\n  si_path() %>% \n    return_latest() %>% \n    read_msd() %>% \n    reshape_msd(clean = T)\n  \n\n# MUNGE -------------------------------------------------------------------\n  \n# VIZ ---------------------------------------------------------------------\n  \n# SPIN DOWN ---------------------------------------------------------------\n\nYou’ll notice a ref_id being stored in the code chunk above. Our team utilizes reference ids in our R scripts to improve our ability to track code to specific analytic products. These reference ids are stored in captions at the bottom of any visualizations or outputs that are produced from our script, so we can more easily reference the corresponding code from our code repositories. They are automatically generated when we create scripts from a snippet template, which uses the following code to generate a unique, 8 character id:\n\nsubstr(digest::sha1(Sys.time()), start = 1, stop = 8)\n\n[1] \"627fd2ce\""
  },
  {
    "objectID": "best_practices.html#commenting-your-code",
    "href": "best_practices.html#commenting-your-code",
    "title": "11  Best practices on writing a script",
    "section": "11.2 Commenting Your Code",
    "text": "11.2 Commenting Your Code\nHaving a script without inline comments makes it much more challenging to debug or decipher what is going on. It is important to add comments (text that follows a #) to chunks of code to provide insights to what is going on. There are a couple of major things to keep in mind.\nFirst is to not over-commenting, which then makes it more challenging to both develop and maintain, but also to debug problems. Each chunk should be able to be described succinctly; if you require lots of explanation your code chunk likely needs be be broken into smaller segments.\nSecondly, when we add comments to a script, by default we typically explain what is going on with our code in plain English. However, it’s much more useful to explain why. Instead of adding an inline comment that you are creating a moving average of variable x, it’s better to explain that you are moving average variable x to identify outliers based on this calculation."
  },
  {
    "objectID": "best_practices.html#additional-resources",
    "href": "best_practices.html#additional-resources",
    "title": "11  Best practices on writing a script",
    "section": "11.3 Additional Resources",
    "text": "11.3 Additional Resources\nTidyverse Style Guide Google’s R Style Guide R4DS Workflows"
  },
  {
    "objectID": "using_github.html#how-to-get-added",
    "href": "using_github.html#how-to-get-added",
    "title": "12  Using our GitHub organization",
    "section": "12.1 How to get added?",
    "text": "12.1 How to get added?\nAnyone can view the code on GitHub, but in order to contribute or or participate in issues or projects, you will need to be added to the USAID-OHA-SI organizational account. You can email one of the organization’s “owners” - Aaron Chafetz (achafetz@usaid.gov), Tim Essam (tessam@usaid.gov), Baboyma Kagniniwa (bkagniniwa@usaid.gov), Karishma Srikanth (ksrikanth@usaid.gov) - with the email address associated with your GitHub account."
  },
  {
    "objectID": "using_github.html#search-the-organizational-space",
    "href": "using_github.html#search-the-organizational-space",
    "title": "12  Using our GitHub organization",
    "section": "12.2 Search the organizational space",
    "text": "12.2 Search the organizational space\nGitHub is a powerful tool because it allows us to collaborate and share our code, with others and our future selves. By committing and pushing code, you make all of your work searchable. This feature becomes a huge asset to others trying to learn or review how previous analyses were run. If you go to GitHub, our organization page, or github.com/search, you can search through all our code.\nFor example, if you were interested in learning about how the across() function is used, you could search org:USAID-OHA-SI mutate across to see all the instances of how we are applying this function from dplyr or you could search for how viral load coverage is calculated, org:USAID-OHA-SI vlc. GitHub has a great reference document for using the powerful search features."
  },
  {
    "objectID": "using_github.html#how-to-navigate",
    "href": "using_github.html#how-to-navigate",
    "title": "12  Using our GitHub organization",
    "section": "12.3 How to navigate",
    "text": "12.3 How to navigate\nThe USAID-OHA-SI organizational account hosts all of our team’s R scripts and packages. Currently we have over 100 repositories on GitHub, so finding what you are looking for can be challenging. One thing to note as well is that we tend to use fun names for projects. So instead of calling a project space “COP planning”, we come up with names loosely related, badboys, as referring to the Will Smith and Martin Lawrence movie about two cops. It’s all our bad attempt at humor but it keeps things fun and interesting. Since the project names are very loosely related, you can look through the Description which will better summarize the project.\nBelow are a few useful repos to review/reference:\n\ngroundhogday: quarterly scripts that we find ourselves needing to use again and again\ncatch-22: one off analytic requests\nagitprop: high level communications visuals typically produced for the OHA Front Office\n\nIn addition to having R projects stored as repositories, we rely on GitHub for hosting our R packages so everyone can access them. Each of our packages have their own websites, built through pkgdown, with documentation and are easily navigable from the SI blog.\nThe package pages are great resources, but sometimes you want to see the code underlying a function or want to suggest a change via a pull request (PR). You can find search through the USAID-OHA-SI account to find the repository and find the code you are looking for."
  },
  {
    "objectID": "using_github.html#when-should-i-create-a-new-repo",
    "href": "using_github.html#when-should-i-create-a-new-repo",
    "title": "12  Using our GitHub organization",
    "section": "12.4 When should I create a new repo?",
    "text": "12.4 When should I create a new repo?\nAs you can see, we have lots of repositories that are in existence. Repositories are essentially projects, so we can think about creating one when our work does not easily fit into another existing repository or is going to be large and complex and needs to stand on its own. For example, if I review targets for Tanzania from their target setting tool, this likely should not be its own repo, but fits either within badboys (SI related support for PEPFAR COPs) or rebooTZ (OHA SI support for Tanzania)."
  },
  {
    "objectID": "using_github.html#how-can-i-contribute",
    "href": "using_github.html#how-can-i-contribute",
    "title": "12  Using our GitHub organization",
    "section": "12.5 How can I contribute",
    "text": "12.5 How can I contribute\nVersion control and capturing all of our coding on GitHub is important for a number reasons:\n\nReduces barriers to collaboration\nProvides a form of back up\nCaptures project evolution\nExperiment without fear\nCommit to transparency\n\nThere are a number of ways in which you can contribute to our community and global good.\n\nSubmit an issue - If you are running into a bug with the code, getting unexpected results, or have a suggestion to make, you can submit a ticket on GitHub. For example, if I have an issue with a date conversion in glamr, I would go to the package repo, github.com/USAID-OHA-SI/glamr and navigate to the “Issues” tab at the top of the repo. There I could select the green “New issue” button, and clearly the descibe the issue/suggestion (check out the Getting Help chapter on writing a reproducible example).\nContribute code or a fix to an existing repo/package - If you have written your own code, you can submit a pull request (PR) on github to get it added to the repo. When working on a shared project, it’s best practice to work on your own branch and then submit a PR to get that branch included in the repo. Clone the repo to your RStudio and then create (checkout) a new branch (this can be done through the git IDE tab within RStudio or can be done in the terminal in RStudio, e.g git checkout -b dev_fix-that-thing). Once you have made the changes and verified the code runs as intended, you can push your branch. At that stage, you can go to the repo on GitHub, navigate to the “Pull requests” tab and then create a new pull request from your dev branch to the main branch. The project or package owner/maintainer will review the PR for inclusion into the repo.\nCreating a new repo : If you have a new project that does not exist elsewhere, you can create a new repo. The “Setting up a project” chapter details how to do this through RStudio, but you can also setup your project on GitHub. Under our organization, select Repositories and then click the green button the right, “New Repository”. Front there you will want to add a (witty) repo name with a solid description. The repo should be public, you should add a README, .gitignore, and MIT license.\n\nFrom there you can clone the project locally, but selecting the green “Code” button, copying the HTTPS url and setting up a version control project in RStudio."
  },
  {
    "objectID": "getting_help.html#additional-resources",
    "href": "getting_help.html#additional-resources",
    "title": "13  Getting help/setting up a reprex",
    "section": "13.1 Additional Resources",
    "text": "13.1 Additional Resources\n\nAsk Better Code Questions (and Get Better Answers) With Reprex\nreprex package\nHelp Me Help You: Creating reproducible examples | RStudio (2018)\nSo you’ve been asked to make a reprex\nFAQ: What’s a reproducible example (reprex) and how do I create one?"
  },
  {
    "objectID": "r_packages.html",
    "href": "r_packages.html",
    "title": "14  R Packages",
    "section": "",
    "text": "Intro\nCreating a new package Setup package structure Set up package - while you can create a new package using devtools, it is much easier to use Rstudio. To create a new package use the Create Project command and select the New Directory option. Select R package on the pop-up screen."
  },
  {
    "objectID": "vignettes.html",
    "href": "vignettes.html",
    "title": "15  Creating a Website and Vignettes for a Package",
    "section": "",
    "text": "Vignettes are great features of R packages that introduce the user to the package’s intended use and functionality. As you build a series of vignettes for package users, you can organize them into a website using the pkgdown package."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chafetz, Aaron H. 2023. “R Guide for Strategic Information\nAdvisors.” Stractegic Info. 1 (1): 00–99. https://doi.org/10.1093/comjnl/27.2.97."
  }
]